{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Standard transformation for validation data\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "# Datasets\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='../datasets/train', transform=train_transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder(root='../datasets/val', transform=val_transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=256, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.conv3 = torch.nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.conv4 = torch.nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        self.conv5 = torch.nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.relu5 = torch.nn.ReLU()\n",
    "        self.conv6 = torch.nn.Conv2d(512, 1024, 3, padding=1)\n",
    "        self.relu6 = torch.nn.ReLU()\n",
    "\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = None\n",
    "        self.fc2 = torch.nn.Linear(1024, 2)\n",
    "\n",
    "        # Dummy forward pass to initialize fc1 with the correct input size\n",
    "        with torch.no_grad():\n",
    "            self._initialize_fc1(torch.zeros(1, 3, 224, 224))\n",
    "\n",
    "    def conv_forward(self, x):\n",
    "        x = self.pool(self.relu1(self.conv1(x)))\n",
    "        x = self.pool(self.relu2(self.conv2(x)))\n",
    "        x = self.pool(self.relu3(self.conv3(x)))\n",
    "        x = self.pool(self.relu4(self.conv4(x)))\n",
    "        x = self.pool(self.relu5(self.conv5(x)))\n",
    "        x = self.pool(self.relu6(self.conv6(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.fc1 is None:\n",
    "            self._initialize_fc1(x)\n",
    "        x = self.conv_forward(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_fc1(self, x):\n",
    "        x = self.conv_forward(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        n_features = x.size(1)\n",
    "        self.fc1 = torch.nn.Linear(n_features, 1024)\n",
    "\n",
    "# Function to run training and validation loop\n",
    "def train_and_evaluate(model, optimizer, scheduler, criterion, train_loader, val_loader, num_epochs=15, patience=5, min_delta=0.001):\n",
    "    epoch_data = []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {val_accuracy} %, Average loss: {val_accuracy}')\n",
    "\n",
    "        if (best_val_loss - avg_val_loss) > min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping triggered at epoch {epoch + 1}')\n",
    "            break\n",
    "\n",
    "        epoch_data.append({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Training Accuracy': train_accuracy,\n",
    "            'Validation Loss': avg_val_loss,\n",
    "            'Validation Accuracy': val_accuracy\n",
    "        })\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return pd.DataFrame(epoch_data), val_accuracy\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    # Define the input shape in the first layer of the neural network\n",
    "    layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(512, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(1024, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    # The new FC layer, you can also add dropout layer here\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    \n",
    "    # Add the final output layer\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Now plot the model\n",
    "tf.keras.utils.plot_model(model, to_file='enhanced_cnn_model.png', show_shapes=True, show_layer_names=True, rankdir='TB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-2,1e-4,1e-3]\n",
    "best_accuracy = 0\n",
    "best_lr = 0\n",
    "\n",
    "# Initialize dictionaries to store metrics for each learning rate\n",
    "all_train_losses = {}\n",
    "all_train_accuracies = {}\n",
    "all_val_losses = {}\n",
    "all_val_accuracies = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = EnhancedCNN().to(device)  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    metrics_df, val_accuracy = train_and_evaluate(model, optimizer, scheduler, criterion, train_loader, val_loader)\n",
    "\n",
    "    # Collect metrics\n",
    "    all_train_losses[lr] = metrics_df['Training Loss'].tolist()\n",
    "    all_train_accuracies[lr] = metrics_df['Training Accuracy'].tolist()\n",
    "    all_val_losses[lr] = metrics_df['Validation Loss'].tolist()\n",
    "    all_val_accuracies[lr] = metrics_df['Validation Accuracy'].tolist()\n",
    "\n",
    "    # Update the best accuracy and learning rate if the current one is better\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        best_lr = lr\n",
    "\n",
    "# Plotting the results\n",
    "sns.set()  # Use seaborn's default style for the plots\n",
    "\n",
    "def plot_metrics(metrics_dict, title):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for lr, metrics in metrics_dict.items():\n",
    "        plt.plot(metrics, label=f'lr={lr}')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot all metrics\n",
    "plot_metrics(all_train_losses, 'Train Loss')\n",
    "plot_metrics(all_train_accuracies, 'Train Accuracy')\n",
    "plot_metrics(all_val_losses, 'Test Loss')\n",
    "plot_metrics(all_val_accuracies, 'Test Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Define a function to perform the prediction on each image\n",
    "def predict_class(image_path, model, val_transform, class_to_idx):\n",
    "    # Load and transform the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = val_transform(image)\n",
    "\n",
    "    # Add a batch dimension\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Model prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Get the class name\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    predicted_class_name = idx_to_class[predicted.item()]\n",
    "    \n",
    "    return predicted_class_name\n",
    "\n",
    "# Assuming val_transform, model, and train_dataset are already defined and available\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "\n",
    "# Loop through each test image and store results\n",
    "predictions = {}\n",
    "for i in range(1, 501):  # Assuming images are named from 1.jpg to 500.jpg\n",
    "    image_path = f'../datasets/test/{i}.jpg'  # Update the path as per your directory structure\n",
    "    predicted_class_name = predict_class(image_path, model, val_transform, class_to_idx)\n",
    "    predictions[image_path] = predicted_class_name\n",
    "\n",
    "# Display the predictions\n",
    "for key, value in predictions.items():\n",
    "    print(f\"{key}, Predicted Class: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = f'PengYangling/IE4483/model{lr}.pth'\n",
    "torch.save(model.state_dict(), checkpoint_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
